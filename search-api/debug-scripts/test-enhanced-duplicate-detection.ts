#!/usr/bin/env npx tsx

/**
 * Debug script for T040: Implement duplicate detection across search sources
 * 
 * This script tests the enhanced duplicate detection implementation:
 * - Testing different detection strategies
 * - Comparing enhanced vs basic duplicate detection
 * - Testing with realistic data from multiple search sources
 * - Performance testing with various dataset sizes
 * - Testing configuration options and custom rules
 */

import {
  resultMergerService,
  SearchResultItem,
  RankedResults,
  MergedResult
} from '../src/services';
import {
  duplicateDetectionService,
  DuplicateDetectionService
} from '../src/services/duplicate-detection.service';
import {
  DetectionStrategy,
  DuplicateType,
  DuplicateDetectionConfig
} from '../src/services/duplicate-detection.interfaces';

// Test data for enhanced duplicate detection
const createMockSearchResults = (source: string, count: number, withDuplicates: boolean = true): RankedResults => {
  const tools = [
    { name: 'React', description: 'JavaScript library for building user interfaces', category: 'frontend', url: 'https://reactjs.org' },
    { name: 'Vue.js', description: 'Progressive JavaScript framework', category: 'frontend', url: 'https://vuejs.org' },
    { name: 'Angular', description: 'Platform for building web applications', category: 'frontend', url: 'https://angular.io' },
    { name: 'Express.js', description: 'Web framework for Node.js', category: 'backend', url: 'https://expressjs.com' },
    { name: 'MongoDB', description: 'NoSQL database program', category: 'database', url: 'https://mongodb.com' },
    { name: 'TypeScript', description: 'Typed superset of JavaScript', category: 'language', url: 'https://typescriptlang.org' },
    { name: 'Docker', description: 'Platform for containerization', category: 'devops', url: 'https://docker.com' }
  ];

  const results: SearchResultItem[] = [];
  
  for (let i = 0; i < count; i++) {
    const tool = tools[i % tools.length];
    const isDuplicate = withDuplicates && i >= tools.length && Math.random() > 0.5;
    
    results.push({
      id: `${source}-${tool.name.toLowerCase()}-${i}`,
      score: 0.9 - (i * 0.05),
      source,
      payload: {
        name: isDuplicate ? tool.name : `${tool.name} v${i + 1}`,
        description: isDuplicate ? tool.description : `${tool.description} - version ${i + 1}`,
        category: tool.category,
        url: tool.url,
        version: isDuplicate ? '1.0.0' : `${i + 1}.0.0`
      },
      metadata: {
        searchTime: 100 + i * 10,
        rank: i + 1,
        source
      }
    });
  }

  return {
    source,
    results,
    totalResults: results.length,
    searchTime: 200,
    metadata: { source, algorithm: 'test' }
  };
};

// Test basic duplicate detection strategies
async function testBasicStrategies(): Promise<void> {
  console.log('\nüß™ Testing Basic Duplicate Detection Strategies');
  console.log('='.repeat(60));
  
  // Test exact ID matching
  console.log('\nüìã Test 1: Exact ID Matching');
  const item1 = {
    id: 'react-1',
    score: 0.9,
    source: 'test',
    payload: { name: 'React', description: 'JS library' },
    metadata: {}
  };
  
  const item2 = {
    id: 'react-1',
    score: 0.85,
    source: 'test2',
    payload: { name: 'React', description: 'JavaScript library' },
    metadata: {}
  };
  
  const idResult = await duplicateDetectionService.areDuplicates(item1, item2);
  console.log(`‚úÖ Exact ID match: ${idResult.isDuplicate ? 'DETECTED' : 'NOT DETECTED'}`);
  console.log(`   Strategy: ${idResult.detectedBy}`);
  console.log(`   Similarity: ${idResult.similarityScore?.toFixed(3)}`);
  console.log(`   Confidence: ${idResult.confidence?.toFixed(3)}`);
  
  // Test content similarity
  console.log('\nüìã Test 2: Content Similarity');
  const item3 = {
    id: 'react-2',
    score: 0.9,
    source: 'test',
    payload: { name: 'React Components', description: 'Library for React components' },
    metadata: {}
  };
  
  const item4 = {
    id: 'react-3',
    score: 0.85,
    source: 'test2',
    payload: { name: 'React Component Library', description: 'Components for React development' },
    metadata: {}
  };
  
  const contentResult = await duplicateDetectionService.areDuplicates(item3, item4);
  console.log(`‚úÖ Content similarity: ${contentResult.isDuplicate ? 'DETECTED' : 'NOT DETECTED'}`);
  console.log(`   Strategy: ${contentResult.detectedBy}`);
  console.log(`   Similarity: ${contentResult.similarityScore?.toFixed(3)}`);
  console.log(`   Field matches: ${JSON.stringify(contentResult.fieldMatches)}`);
  
  // Test version-aware matching
  console.log('\nüìã Test 3: Version-Aware Matching');
  const item5 = {
    id: 'react-v18',
    score: 0.9,
    source: 'test',
    payload: { name: 'React v18.0.0', description: 'JS library v18', version: '18.0.0' },
    metadata: {}
  };
  
  const item6 = {
    id: 'react-v17',
    score: 0.85,
    source: 'test2',
    payload: { name: 'React v17.0.0', description: 'JS library v17', version: '17.0.0' },
    metadata: {}
  };
  
  const versionResult = await duplicateDetectionService.areDuplicates(item5, item6);
  console.log(`‚úÖ Version-aware: ${versionResult.isDuplicate ? 'DETECTED' : 'NOT DETECTED'}`);
  console.log(`   Strategy: ${versionResult.detectedBy}`);
  console.log(`   Duplicate type: ${versionResult.duplicateType}`);
  console.log(`   Similarity: ${versionResult.similarityScore?.toFixed(3)}`);
}

// Test enhanced vs basic duplicate detection in result merger
async function testEnhancedVsBasicDetection(): Promise<void> {
  console.log('\nüß™ Testing Enhanced vs Basic Duplicate Detection in Result Merger');
  console.log('='.repeat(80));
  
  // Create test data with various types of duplicates
  const vectorResults = createMockSearchResults('vector', 8, true);
  const traditionalResults = createMockSearchResults('traditional', 8, true);
  
  // Add some specific duplicates across sources
  traditionalResults.results[2] = {
    ...vectorResults.results[1], // Exact content duplicate
    id: 'traditional-react-dup',
    score: 0.85,
    source: 'traditional'
  };
  
  traditionalResults.results[4] = {
    ...vectorResults.results[3],
    id: 'traditional-express-dup',
    payload: {
      ...vectorResults.results[3].payload,
      name: 'Express.js Framework', // Slight variation
      description: 'Web framework for Node.js applications'
    },
    score: 0.82,
    source: 'traditional'
  };
  
  const totalInputItems = vectorResults.results.length + traditionalResults.results.length;
  
  console.log(`\nüìä Test Data:`);
  console.log(`   Vector search: ${vectorResults.results.length} items`);
  console.log(`   Traditional search: ${traditionalResults.results.length} items`);
  console.log(`   Total input: ${totalInputItems} items`);
  
  // Test with basic duplicate detection
  console.log('\nüìã Test 1: Basic Duplicate Detection');
  const basicStart = Date.now();
  const basicResults = await resultMergerService.mergeResults(
    [vectorResults, traditionalResults],
    {
      enableDeduplication: true,
      useEnhancedDuplicateDetection: false,
      deduplicationThreshold: 0.9
    }
  );
  const basicTime = Date.now() - basicStart;
  
  console.log(`‚úÖ Basic detection completed in ${basicTime}ms`);
  console.log(`   Unique results: ${basicResults.length}`);
  console.log(`   Duplicates removed: ${totalInputItems - basicResults.length}`);
  console.log(`   Processing rate: ${(totalInputItems / (basicTime / 1000)).toFixed(0)} items/sec`);
  
  // Test with enhanced duplicate detection
  console.log('\nüìã Test 2: Enhanced Duplicate Detection');
  const enhancedStart = Date.now();
  const enhancedResults = await resultMergerService.mergeResults(
    [vectorResults, traditionalResults],
    {
      enableDeduplication: true,
      useEnhancedDuplicateDetection: true,
      duplicateDetectionConfig: {
        enabled: true,
        strategies: [
          DetectionStrategy.EXACT_ID,
          DetectionStrategy.CONTENT_SIMILARITY,
          DetectionStrategy.VERSION_AWARE,
          DetectionStrategy.FUZZY_MATCH
        ],
        thresholds: {
          contentSimilarity: 0.8,
          versionAware: 0.85,
          fuzzyMatch: 0.7
        },
        logging: {
          enabled: true,
          level: 'info',
          includeStats: true
        }
      }
    }
  );
  const enhancedTime = Date.now() - enhancedStart;
  
  console.log(`‚úÖ Enhanced detection completed in ${enhancedTime}ms`);
  console.log(`   Unique results: ${enhancedResults.length}`);
  console.log(`   Duplicates removed: ${totalInputItems - enhancedResults.length}`);
  console.log(`   Processing rate: ${(totalInputItems / (enhancedTime / 1000)).toFixed(0)} items/sec`);
  
  // Compare results
  console.log('\nüìä Comparison:');
  console.log(`   Results: Basic ${basicResults.length} vs Enhanced ${enhancedResults.length}`);
  console.log(`   Duplicates: Basic ${totalInputItems - basicResults.length} vs Enhanced ${totalInputItems - enhancedResults.length}`);
  console.log(`   Enhancement: Found ${(totalInputItems - enhancedResults.length) - (totalInputItems - basicResults.length)} more duplicates`);
  console.log(`   Performance: ${((enhancedTime - basicTime) / basicTime * 100).toFixed(1)}% overhead`);
  
  // Show top results
  console.log('\nüèÜ Top 3 Results (Enhanced):');
  enhancedResults.slice(0, 3).forEach((result, index) => {
    console.log(`   ${index + 1}. ${result.payload?.name} (RRF: ${result.rrfScore.toFixed(4)})`);
    console.log(`      Sources: ${Object.keys(result.originalRankings).join(', ')}`);
    console.log(`      Source Count: ${result.sourceCount}`);
  });
}

// Test different detection strategies
async function testDifferentStrategies(): Promise<void> {
  console.log('\nüß™ Testing Different Detection Strategies');
  console.log('='.repeat(60));
  
  // Create test data with specific duplicate types
  const testData: SearchResultItem[] = [
    {
      id: 'react-1',
      score: 0.9,
      source: 'test',
      payload: { name: 'React', description: 'JS library', url: 'https://reactjs.org', version: '18.0.0' },
      metadata: {}
    },
    {
      id: 'react-2', // Same name, different ID
      score: 0.85,
      source: 'test2',
      payload: { name: 'React', description: 'JavaScript library', url: 'https://reactjs.org', version: '18.0.0' },
      metadata: {}
    },
    {
      id: 'react-3', // Same tool, different version
      score: 0.8,
      source: 'test3',
      payload: { name: 'React v17.0.0', description: 'JS library', url: 'https://reactjs.org', version: '17.0.0' },
      metadata: {}
    },
    {
      id: 'react-4', // Similar content
      score: 0.75,
      source: 'test4',
      payload: { name: 'React Components', description: 'Library for React UI', url: 'https://reactjs.org', version: '18.0.0' },
      metadata: {}
    },
    {
      id: 'vue-1', // Different tool
      score: 0.9,
      source: 'test',
      payload: { name: 'Vue.js', description: 'Progressive framework', url: 'https://vuejs.org', version: '3.0.0' },
      metadata: {}
    }
  ];
  
  const strategies = [
    { name: 'Exact ID Only', strategies: [DetectionStrategy.EXACT_ID] },
    { name: 'Content Similarity Only', strategies: [DetectionStrategy.CONTENT_SIMILARITY] },
    { name: 'Version Aware Only', strategies: [DetectionStrategy.VERSION_AWARE] },
    { name: 'Fuzzy Match Only', strategies: [DetectionStrategy.FUZZY_MATCH] },
    { name: 'All Strategies', strategies: [DetectionStrategy.EXACT_ID, DetectionStrategy.CONTENT_SIMILARITY, DetectionStrategy.VERSION_AWARE, DetectionStrategy.FUZZY_MATCH] }
  ];
  
  for (const strategy of strategies) {
    console.log(`\nüìã Testing ${strategy.name}`);
    
    const result = await duplicateDetectionService.detectDuplicates(testData, {
      enabled: true,
      strategies: strategy.strategies as DetectionStrategy[],
      thresholds: {
        contentSimilarity: 0.8,
        versionAware: 0.85,
        fuzzyMatch: 0.7
      },
      logging: { enabled: false }
    });
    
    console.log(`   Input: ${testData.length}, Output: ${result.deduplicatedItems.length}`);
    console.log(`   Duplicates found: ${testData.length - result.deduplicatedItems.length}`);
    console.log(`   Duplicate groups: ${result.duplicateGroups.length}`);
    console.log(`   Processing time: ${result.stats.processingTime}ms`);
    
    if (result.duplicateGroups.length > 0) {
      console.log(`   Duplicate groups:`);
      result.duplicateGroups.forEach((group, index) => {
        console.log(`     ${index + 1}. ${group.type} (${group.detectedBy}): ${group.items.length} items`);
      });
    }
  }
}

// Test configuration options
async function testConfigurationOptions(): Promise<void> {
  console.log('\nüß™ Testing Configuration Options');
  console.log('='.repeat(60));
  
  const testData = createMockSearchResults('test', 10, true).results;
  
  // Test different thresholds
  console.log('\nüìã Test 1: Different Similarity Thresholds');
  const thresholds = [0.5, 0.7, 0.8, 0.9, 0.95];
  
  for (const threshold of thresholds) {
    const result = await duplicateDetectionService.detectDuplicates(testData, {
      enabled: true,
      strategies: [DetectionStrategy.CONTENT_SIMILARITY],
      thresholds: { contentSimilarity: threshold },
      logging: { enabled: false }
    });
    
    console.log(`   Threshold ${threshold}: ${testData.length - result.deduplicatedItems.length} duplicates found`);
  }
  
  // Test different field weights
  console.log('\nüìã Test 2: Different Field Weights');
  const weightConfigs = [
    { name: 'Name Only', weights: { name: 1.0, description: 0, url: 0, category: 0 } },
    { name: 'Description Only', weights: { name: 0, description: 1.0, url: 0, category: 0 } },
    { name: 'Balanced', weights: { name: 0.5, description: 0.3, url: 0.15, category: 0.05 } },
    { name: 'Name Heavy', weights: { name: 0.8, description: 0.1, url: 0.05, category: 0.05 } }
  ];
  
  for (const config of weightConfigs) {
    const result = await duplicateDetectionService.detectDuplicates(testData, {
      enabled: true,
      strategies: [DetectionStrategy.CONTENT_SIMILARITY],
      thresholds: { contentSimilarity: 0.8 },
      fieldWeights: config.weights as any,
      logging: { enabled: false }
    });
    
    console.log(`   ${config.name}: ${testData.length - result.deduplicatedItems.length} duplicates found`);
  }
  
  // Test performance options
  console.log('\nüìã Test 3: Performance Options');
  const performanceConfigs = [
    { name: 'No Cache, No Parallel', config: { enableCache: false, enableParallel: false } },
    { name: 'Cache Only', config: { enableCache: true, enableParallel: false } },
    { name: 'Parallel Only', config: { enableCache: false, enableParallel: true, parallelWorkers: 4 } },
    { name: 'Cache + Parallel', config: { enableCache: true, enableParallel: true, parallelWorkers: 4 } }
  ];
  
  for (const config of performanceConfigs) {
    const startTime = Date.now();
    const result = await duplicateDetectionService.detectDuplicates(testData, {
      enabled: true,
      strategies: [DetectionStrategy.CONTENT_SIMILARITY, DetectionStrategy.VERSION_AWARE],
      thresholds: { contentSimilarity: 0.8, versionAware: 0.85 },
      performance: config.config as any,
      logging: { enabled: false }
    });
    const processingTime = Date.now() - startTime;
    
    console.log(`   ${config.name}: ${processingTime}ms (${result.stats.cacheStats?.hitRate ? (result.stats.cacheStats.hitRate * 100).toFixed(1) + '% hit rate' : 'no cache'})`);
  }
}

// Test custom rules
async function testCustomRules(): Promise<void> {
  console.log('\nüß™ Testing Custom Rules');
  console.log('='.repeat(60));
  
  const service = new DuplicateDetectionService();
  
  // Add a custom rule for frontend tools
  const frontendRule = {
    id: 'frontend-tools',
    name: 'Frontend Tools Rule',
    strategy: DetectionStrategy.CONTENT_SIMILARITY,
    priority: 1,
    handler: (item1: SearchResultItem, item2: SearchResultItem) => {
      const cat1 = item1.payload?.category || '';
      const cat2 = item2.payload?.category || '';
      const name1 = item1.payload?.name || '';
      const name2 = item2.payload?.name || '';
      
      // Consider frontend tools with similar names as duplicates
      return cat1 === 'frontend' && cat2 === 'frontend' && 
             (name1.toLowerCase().includes('react') && name2.toLowerCase().includes('react') ||
              name1.toLowerCase().includes('vue') && name2.toLowerCase().includes('vue'));
    },
    enabled: true
  };
  
  service.addCustomRule(frontendRule);
  
  // Test with custom rule
  const testData: SearchResultItem[] = [
    {
      id: 'react-1',
      score: 0.9,
      source: 'test',
      payload: { name: 'React Components', category: 'frontend' },
      metadata: {}
    },
    {
      id: 'react-2',
      score: 0.85,
      source: 'test2',
      payload: { name: 'React Router', category: 'frontend' },
      metadata: {}
    },
    {
      id: 'vue-1',
      score: 0.9,
      source: 'test',
      payload: { name: 'Vue Components', category: 'frontend' },
      metadata: {}
    },
    {
      id: 'vue-2',
      score: 0.85,
      source: 'test2',
      payload: { name: 'Vue Router', category: 'frontend' },
      metadata: {}
    },
    {
      id: 'express-1',
      score: 0.9,
      source: 'test',
      payload: { name: 'Express.js', category: 'backend' },
      metadata: {}
    }
  ];
  
  console.log('\nüìã Test with custom rule enabled');
  const resultWithRule = await service.detectDuplicates(testData, {
    enabled: true,
    strategies: [DetectionStrategy.CONTENT_SIMILARITY],
    thresholds: { contentSimilarity: 0.8 },
    logging: { enabled: false }
  });
  
  console.log(`   Input: ${testData.length}, Output: ${resultWithRule.deduplicatedItems.length}`);
  console.log(`   Duplicates found: ${testData.length - resultWithRule.deduplicatedItems.length}`);
  
  // Remove custom rule and test again
  service.removeCustomRule('frontend-tools');
  
  console.log('\nüìã Test with custom rule disabled');
  const resultWithoutRule = await service.detectDuplicates(testData, {
    enabled: true,
    strategies: [DetectionStrategy.CONTENT_SIMILARITY],
    thresholds: { contentSimilarity: 0.8 },
    logging: { enabled: false }
  });
  
  console.log(`   Input: ${testData.length}, Output: ${resultWithoutRule.deduplicatedItems.length}`);
  console.log(`   Duplicates found: ${testData.length - resultWithoutRule.deduplicatedItems.length}`);
  console.log(`   Custom rule matches: ${resultWithRule.duplicateGroups.length - resultWithoutRule.duplicateGroups.length}`);
  console.log(`   Difference: ${(testData.length - resultWithRule.deduplicatedItems.length) - (testData.length - resultWithoutRule.deduplicatedItems.length)} more duplicates with custom rule`);
}

// Main test execution
async function main(): Promise<void> {
  console.log('üöÄ T040: Enhanced Duplicate Detection Debug Test Suite');
  console.log('Testing enhanced duplicate detection across search sources');
  
  try {
    await testBasicStrategies();
    console.log('\n' + '='.repeat(80));
    
    await testEnhancedVsBasicDetection();
    console.log('\n' + '='.repeat(80));
    
    await testDifferentStrategies();
    console.log('\n' + '='.repeat(80));
    
    await testConfigurationOptions();
    console.log('\n' + '='.repeat(80));
    
    await testCustomRules();
    console.log('\n' + '='.repeat(80));
    
    console.log('\nüéâ Enhanced duplicate detection test suite completed successfully!');
    console.log('‚úÖ All critical requirements met for T040');
    
    // Summary
    console.log('\nüìã Implementation Summary:');
    console.log('‚úÖ Enhanced duplicate detection service created');
    console.log('‚úÖ Multiple detection strategies implemented');
    console.log('‚úÖ Configurable thresholds and weights');
    console.log('‚úÖ Custom rules support');
    console.log('‚úÖ Performance optimizations (caching, parallel processing)');
    console.log('‚úÖ Integration with result merger service');
    console.log('‚úÖ Comprehensive test coverage');
    
  } catch (error) {
    console.error('\n‚ùå Test suite failed:', error);
    process.exit(1);
  }
}

// Run the test if this file is executed directly
if (require.main === module) {
  main()
    .then(() => {
      console.log('\n‚úÖ Enhanced duplicate detection debug script completed successfully');
      process.exit(0);
    })
    .catch((error) => {
      console.error('\n‚ùå Debug script failed:', error);
      process.exit(1);
    });
}

export { main };
